\section{Physics Analysis}
\label{sec:analysis}

Data analysis broadly refers to the ensemble of tools and techniques used to extract constraints on the physical properties of the muon. Data analysis tasks include, for example, measurements of muon branching fractions and capture rates, comparisons between data and Monte Carlo simulations, extraction of calibration and detector performance parameters, or search for new phenomena. For these tasks, the software framework used for large-scale data processing might not be the most appropriate solution. This difference may not necessarily arise from missing functionalities or technological limitations in the large-scale production framework but might reflect the preference of analysts to trade capabilities in favor of flexibility and simplicity. The usage of external tools, such as machine learning or fit algorithms, might also be easier within a custom framework. Similarly, reduced data analysis samples (aka ntuples) might be more convenient to analyze than data containing the full event information. These samples could be structured differently from the data recorded by the detector (e.g. columnar structure) to improve the processing performance as well. This section describes the analysis frameworks and reduced data samples used by the experiment, together with a generic reference analysis based on these tools. While the development of a blinding strategy is of high importance for the collaboration, it is not expected to have a significant impact on computing and won't be discussed any further in this document. 




\subsection{Analysis Frameworks and Interfaces}

Offline analysis can be facilitated by using reduced data sets ("ntuples") consisting of a smaller set of physics variables deemed most useful for analyses. Information about low-level (hits) and high-level (tracks, clusters) products may need to be stored during commissioning and early data-taking periods. As the experiment matures, reduced ntupling scheme where only information from high-level data products is stored may become the default. Analysis groups will access these ntuples with either ROOT- or Python-based analysis scripts to create plots and perform statistical inferences to derive results.

To ensure operability on both FNAL and local resources, the ntuples data are stored as fundamental types instead of containing Mu2e-specific data products, removing the dependency on the full Mu2e software environment. Using the same assumptions and mock data samples as for the reconstruction output, the size of a ntuple dataset is estimated to be of the order of 100 GB (1 TB) if hit-level information is discarded (stored), small enough to be stored on persistent dCache (to avoid pre-staging the files from tape) or even locally. The simpler structure also translates into a shallower learning curve for new users since it can be easily accessed with ROOT and/or Python, the latter of which in particular is a common language used by early-career researchers.

Mu2e currently has two ntuple frameworks: TrkAna and Stntuple. Both output ROOT-based structures with data organized into event rows and containing reconstructed information extracted from Mu2e data products associated with the tracker, calorimeter, and CRV, as well as Monte Carlo truth information. TrkAna provides a simple ROOT TTree structure that can be accessed with ROOT or Python. Stntuple provides a separate lightweight interactive ntuple-based analysis framework based on that used by the CDF experiment at Fermilab. The Stntuple framework was ported to Mu2e and has evolved to meet the experiment's needs over several years. It supports multiple job configurations, interfaces with the data handling system, and has a built-in 2D event display. Stntuple was used for the Run-1 sensitivity estimate~\cite{Mu2e:2022ggl} and TrkAna is used for current mock data analysis efforts and to study cosmic ray alignment in the extracted position.

The framework is expected to evolve significantly in the near future with the definition of a single ntuple format satisfying most analysis needs and the development of interfaces with  modern analysis tools. This ntuple will necessarily have a "jagged" structure. For example, there will be different numbers and types (e.g. electron, muon) of reconstructed tracks in an event, and each track will include fit results from the Kalman fitter at different segments along the track (e.g. entrance of the tracker). The framework will provide simple interfaces to analyzers to manage this dimensional complexity and reduce the learning curve.

Analyzers will use either ROOT or Python to perform their analyses. ROOT-based analyses will use C/C++ macros, and Python-based analyses will use Python macros and/or Python notebooks. The ntuple is stored as a ROOT TTree so ROOT-based analyses will either loop through the TTree directly or use RDataFrames. RDataFrames have the advantage of performing "lazy" histogramming (i.e. define all cuts and histograms before looping through the data) and offering a transparent use of multi-threading capabilities. However, this would require code development to write RNtuples instead of TTrees, and we plan to evaluate the cost-benefit of this work during the long shutdown after Run 1. Python-based analyses can access the data using ROOT via PyROOT or via the Python packages uproot and awkward array. Python-based analyzers can also use a wide range of available Python packages (e.g. numpy, scipy, hist) to perform their analyses. A common analysis environment is required to aid interoperability between groups and to ensure reproducible results. For ROOT-based analyses, a standard ROOT installation is maintained in Mu2e Offline, while a virtual environment will be provided for Python that can be easily recreated on local machines with either the venv or conda package managers. Tutorials and documentation of both Python- and ROOT C++-style analyses will be maintained throughout the experiment's lifetime. 

Machine learning (ML) algorithms are expected to play an important role in analysis-related tasks. Track quality and particle identification neural networks have already been trained in Python (with Tensorflow) and then evaluated in Mu2e Offline during the ntupling stage. For these, the ROOT TMVA::SOFIE interface is used to produce the C++ code to perform the calculation. New algorithms developed within the analysis groups will either be converted using TMVA::SOFIE and evaluated in the ntuple stage, or a common interface will be developed so that these tools are accessible to all analysis groups. ML algorithm training and other computing-intensive tasks (e.g. statistical inference with a large number of nuisance parameters) will leverage hardware accelerators and high-performance computing architectures to improve performance. The Elastic Analysis Facility (EAF) at FNAL could also be used to scale up data analysis: analysts can prototype their workflow on a subset of the data before seamlessly processing the full dataset. In any case, the computing needs for analysis are expected to be significantly lower than those needed for simulation and reconstruction.


\subsection{Reference Analysis}
% Some of the original material was moved to simulation or other section.
The Reference Analysis is developed to quantify the impact of software and algorithmic changes on the physics performance of the experiment; to prototype analysis tool; and to provide a cross-check to analysis groups. It takes input from the standard analysis framework in the form of reconstructed Mock Data developed using the output of large-scale ensemble production (see Section~\ref{subsec:ensembles}). In ensemnbles, conversion signals are combined with DIO tail backgrounds, cosmic backgrounds, radiative pion and muon capture backgrounds, and pile-up. The pile-up model contains contributions from neutral particles, beam electrons, and other muon processes such as decay in flight. The simulated data are then passed through the digitization and reconstruction framework to create samples similar to the data that will be collected by the DAQ system. 

Datasets equivalent to a year of data taking are created for two different $R_{\mu e}$, plus a no-signal scenario. A corresponding set of samples for the $\mu^{-}N \rightarrow e^{+}N'$ (including leading log corrections) is also produced. Digitization and reconstruction are simulated under two sets of calibration conditions: perfect and best. The "perfect" scenario describes a situation where the detector and digitization parameters behave in an ideal way, while the "best" scenario assumes more realistic conditions. As calibration algorithms evolve, more diverse sets of conditions could be simulated.

The current Reference Analysis contains signal extraction derived from two complementary and independent strategies: a simple counting experiment and an unbinned maximum likelihood fit. A few sources of systematic uncertainties will be added as nuisance parameters into the fit. Work to integrate the reference analysis into the validation workflow to track the evolution of reconstruction and analysis codes has begun.
